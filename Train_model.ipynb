{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef12e82-7656-417a-a5cb-2c00bc35c2e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import YOLO model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-cls.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b275609e-533f-466d-803d-592295a5fc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mshuffle\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/home/rewan/.local/share/jupyter/runtime/kernel-21b9db2b-4048-4520-b8f5-57d9f7827c45.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'pose', 'detect', 'classify', 'segment', 'obb'}\n                MODE (required) is one of {'track', 'val', 'benchmark', 'train', 'predict', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['heatmap', 'queue', 'speed', 'workout', 'analytics', 'trackzone', 'inference'] source=\"path/to/video/file.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 1\u001b[0m\n    model.train(data='data', epochs=10, shuffle= True)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/ultralytics/engine/model.py:800\u001b[0m in \u001b[1;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/ultralytics/models/yolo/classify/train.py:40\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/ultralytics/engine/trainer.py:101\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/ultralytics/cfg/__init__.py:298\u001b[0m in \u001b[1;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/ultralytics/cfg/__init__.py:485\u001b[0;36m in \u001b[0;35mcheck_dict_alignment\u001b[0;36m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mshuffle\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/home/rewan/.local/share/jupyter/runtime/kernel-21b9db2b-4048-4520-b8f5-57d9f7827c45.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'pose', 'detect', 'classify', 'segment', 'obb'}\n                MODE (required) is one of {'track', 'val', 'benchmark', 'train', 'predict', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['heatmap', 'queue', 'speed', 'workout', 'analytics', 'trackzone', 'inference'] source=\"path/to/video/file.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "model.train(data='data', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d10be-0b7d-4ed2-960e-d4f0eb99a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(\"8.jpeg\")\n",
    "result = results[0]  # Access the first (and possibly only) result\n",
    "\n",
    "# Access the probabilities for classification\n",
    "probs = result.probs\n",
    "\n",
    "# Get the index of the class with the highest probability\n",
    "predicted_class_index = probs.top1  # This is the index of the predicted class\n",
    "\n",
    "# Get the confidence of the top prediction\n",
    "confidence = probs.top1conf  # Confidence of the predicted class\n",
    "\n",
    "# Get the class name using the index\n",
    "predicted_class = result.names[predicted_class_index]  # Get predicted class name\n",
    "\n",
    "text = f\"{predicted_class}: {confidence*100:.2f}%\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f726f-5a95-4e53-bd03-adf72b16ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/classify/train/weights/best.pt\")\n",
    "results = model.predict(\"OIP.jpeg\")\n",
    "result = results[0]  # Access the first (and possibly only) result\n",
    "\n",
    "probs = result.probs\n",
    "\n",
    "predicted_class_index = probs.top1  # This is the index of the predicted class\n",
    "\n",
    "# Get the confidence of the top prediction\n",
    "confidence = probs.top1conf  # Confidence of the predicted class\n",
    "\n",
    "# Get the class name using the index\n",
    "predicted_class = result.names[predicted_class_index]  # Get predicted class name\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"OIP.jpeg\")\n",
    "height, width, _ = image.shape\n",
    "\n",
    "rect_top_left = (0, 0)\n",
    "rect_bottom_right = (width, 30)\n",
    "\n",
    "# Define the position and size for the rectangle and text\n",
    "text =  f\"{predicted_class}: {confidence*100:.2f}%\"\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 1\n",
    "color = (255, 255, 255)\n",
    "thickness = 2\n",
    "\n",
    "# Draw a solid rectangle behind the text\n",
    "cv2.rectangle(image, rect_top_left, rect_bottom_right, (0, 255, 0), -1)\n",
    "\n",
    "# Add the text on top of the rectangle\n",
    "cv2.putText(image, text, (5, 25), font, font_size, color, thickness)\n",
    "\n",
    "# Alternatively, to display with OpenCV in a window\n",
    "cv2.imshow(\"Prediction Result\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ab916-e416-4ee9-be68-ce8192c6e862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
